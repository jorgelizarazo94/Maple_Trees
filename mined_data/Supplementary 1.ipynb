{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecd55ab6",
   "metadata": {},
   "source": [
    "# Supplementary 1\n",
    "\n",
    "Jorge Lizarazo & Emna Gharbia\n",
    "\n",
    "<div style=\"text-align: left\"> \n",
    "This document outlines the process of loading and merging forestry data from a GeoPackage file using Fiona Python library. \n",
    "</div>\n",
    "\n",
    "There are the libraries used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db9cd61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n",
    "import pandas as pd\n",
    "from dask import delayed, compute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eb097a",
   "metadata": {},
   "source": [
    "## Listing Available Layers\n",
    "<div style=\"text-align: right\"> \n",
    "Then we create an object for our GeoPackage file called input_file in order to use it. We created a function to list all available layers in the GeoPackage file to understand the structure and contents of the dataset.\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ab982fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available layers: ['pee_ori', 'meta_ori', 'vue_peup_etage_ori', 'vue_peup_essence_ori', 'vue_peup_meta_ori', 'etage_ori', 'essence_ori', 'layer_styles']\n",
      "Columns in layer 'pee_ori': ['geocode', 'origine', 'an_origine', 'perturb', 'an_perturb', 'reb_ess1', 'reb_ess2', 'reb_ess3', 'et_domi', 'part_str', 'type_couv', 'gr_ess', 'cl_dens', 'cl_haut', 'cl_age', 'etagement', 'couv_gaule', 'cl_pent', 'dep_sur', 'cl_drai', 'type_eco', 'co_ter', 'type_ter', 'strate', 'met_at_str', 'superficie', 'toponyme', 'no_prg', 'ver_prg', 'shape_length', 'shape_area']\n",
      "Columns in layer 'meta_ori': ['geocode', 'latitude', 'longitude', 'no_prg', 'ver_prg', 'ver_carto', 'ver_eco', 'ver_cmp', 'statut_acq', 'met_prod', 'pro_sou', 'an_pro_sou', 'an_saisie', 'met_ori', 'pro_ori', 'an_pro_ori', 'resolution', 'or_cl_pent', 'correction', 'dt_correct', 'ty_correct', 'in_etage', 'in_essence', 'us_for', 'in_son_pee', 'no_uco', 'in_cmp_pee', 'in_climat', 'in_contr', 'in_produ', 'in_station', 'in_bois', 'in_biom']\n",
      "Columns in layer 'vue_peup_etage_ori': ['geocode', 'etage', 'ty_couv_et', 'densite', 'hauteur', 'cl_age_et', 'eta_ess_pc', 'origine', 'an_origine', 'perturb', 'an_perturb', 'type_couv', 'gr_ess', 'cl_dens', 'cl_haut', 'cl_age', 'part_str', 'etagement', 'et_domi', 'couv_gaule', 'cl_pent', 'dep_sur', 'cl_drai', 'type_eco', 'type_ter', 'strate', 'met_at_str', 'no_prg', 'ver_prg', 'superficie']\n",
      "Columns in layer 'vue_peup_essence_ori': ['geocode', 'etage', 'essence', 'st_ess_pc', 'origine', 'an_origine', 'perturb', 'an_perturb', 'type_couv', 'gr_ess', 'cl_dens', 'cl_haut', 'cl_age', 'part_str', 'etagement', 'et_domi', 'couv_gaule', 'cl_pent', 'dep_sur', 'cl_drai', 'type_eco', 'type_ter', 'strate', 'met_at_str', 'no_prg', 'ver_prg', 'superficie']\n",
      "Columns in layer 'vue_peup_meta_ori': ['geocode', 'origine', 'an_origine', 'perturb', 'an_perturb', 'type_couv', 'gr_ess', 'cl_dens', 'cl_haut', 'cl_age', 'part_str', 'etagement', 'et_domi', 'couv_gaule', 'cl_pent', 'dep_sur', 'cl_drai', 'type_eco', 'co_ter', 'type_ter', 'strate', 'met_at_str', 'no_prg', 'ver_prg', 'superficie', 'latitude', 'longitude', 'no_prg:1', 'ver_prg:1', 'ver_carto', 'ver_eco', 'ver_cmp', 'statut_acq', 'met_prod', 'pro_sou', 'an_pro_sou', 'an_saisie', 'met_ori', 'pro_ori', 'an_pro_ori', 'resolution', 'or_cl_pent', 'correction', 'dt_correct', 'ty_correct', 'in_etage', 'in_essence', 'us_for', 'in_son_pee', 'no_uco', 'in_cmp_pee', 'in_climat', 'in_contr', 'in_produ', 'in_station', 'in_bois', 'in_biom']\n",
      "Columns in layer 'etage_ori': ['geocode', 'etage', 'ty_couv_et', 'densite', 'hauteur', 'cl_age_et', 'eta_ess_pc']\n",
      "Columns in layer 'essence_ori': ['geocode', 'etage', 'essence', 'st_ess_pc']\n",
      "Columns in layer 'layer_styles': ['f_table_catalog', 'f_table_schema', 'f_table_name', 'f_geometry_column', 'styleName', 'styleQML', 'styleSLD', 'useAsDefault', 'description', 'owner', 'ui', 'update_time']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "input_file = \"CARTE_ECO_ORI_PROV.gpkg\"\n",
    "\n",
    "# List available layers\n",
    "layers = fiona.listlayers(input_file)\n",
    "print(\"Available layers:\", layers)\n",
    "\n",
    "# Function to read and display columns of each layer\n",
    "def list_layer_columns(input_file, layer):\n",
    "    with fiona.open(input_file, layer=layer) as src:\n",
    "        columns = list(src.schema['properties'].keys())\n",
    "        print(f\"Columns in layer '{layer}': {columns}\")\n",
    "\n",
    "# Iterate over each layer and display its columns\n",
    "for layer in layers:\n",
    "    list_layer_columns(input_file, layer)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45888ac",
   "metadata": {},
   "source": [
    "## Selecting and Taking off Specific Columns\n",
    "<div style=\"text-align: right\"> \n",
    "We use the read_layer_attributes function to read specific columns from each layer. This function leverages fiona for efficient data loading and Dask for parallel processing. \n",
    " </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7839532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@delayed\n",
    "def read_layer_attributes(input_file, layer, columns):\n",
    "    with fiona.open(input_file, layer=layer) as src:\n",
    "        records = [{col: feat['properties'][col] for col in columns} for feat in src]\n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86d5710",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> \n",
    "We load the layers concurrently using Dask to improve performance.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81e70401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define las columns you want to load for each layer\n",
    "meta_ori_columns = ['latitude', 'longitude', 'no_uco', 'in_essence', 'geocode']\n",
    "pee_ori_columns = ['an_origine', 'type_ter', 'superficie', 'no_prg',\n",
    "                               'shape_length', 'shape_area', 'geocode']\n",
    "vue_peup_etage_ori_columns = ['etage', 'densite', 'cl_age_et', 'cl_age',\n",
    "                              'geocode']\n",
    "vue_peup_essence_ori_columns = ['essence', 'geocode', 'st_ess_pc']\n",
    "\n",
    "\n",
    "# Load layers concurrently using fiona\n",
    "meta_ori_d = read_layer_attributes(input_file, 'meta_ori', meta_ori_columns)\n",
    "pee_ori_d = read_layer_attributes(input_file, 'pee_ori', pee_ori_columns)\n",
    "stations_for_pee_ori_d = read_layer_attributes(input_file, 'vue_peup_etage_ori',\n",
    "                                               vue_peup_etage_ori_columns)\n",
    "vue_peup_essence_ori_d = read_layer_attributes(input_file, 'vue_peup_essence_ori',\n",
    "                                               vue_peup_essence_ori_columns)\n",
    "# Compute the results\n",
    "meta_ori_d, pee_ori_d, stations_for_pee_ori_d, vue_peup_essence_ori_d = compute(\n",
    "    meta_ori_d, pee_ori_d, stations_for_pee_ori_d, vue_peup_essence_ori_d\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c3115f",
   "metadata": {},
   "source": [
    "## Merging Datasets\n",
    "<div style=\"text-align: right\"> \n",
    "We perform join operations on the geocode column to merge the datasets.\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19c9e9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_ori_d['geocode'] = meta_ori_d['geocode'].astype(str)\n",
    "pee_ori_d['geocode'] = pee_ori_d['geocode'].astype(str)\n",
    "stations_for_pee_ori_d['geocode'] = stations_for_pee_ori_d['geocode'].astype(str)\n",
    "\n",
    "\n",
    "# Merge datasets on geocode\n",
    "merged_df = meta_ori_d.merge(pee_ori_d, on='geocode', how='inner')\n",
    "merged_df = merged_df.merge(stations_for_pee_ori_d, on='geocode', how='inner')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55daae2",
   "metadata": {},
   "source": [
    "## Exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5593c20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved to: data_final_forestry.csv\n"
     ]
    }
   ],
   "source": [
    "# Define output file paths\n",
    "csv_output_file = \"data_final_forestry.csv\"\n",
    "#json_output_file = \"merged_data_\".json\"\n",
    "\n",
    "# Export the merged dataframe to CSV\n",
    "merged_df.to_csv(csv_output_file, index=False)\n",
    "\n",
    "# Export the merged dataframe to JSON\n",
    "#merged_df.to_json(json_output_file, orient='records', lines=True)\n",
    "\n",
    "print(f\"CSV file saved to: {csv_output_file}\")\n",
    "#print(f\"JSON file saved to: {json_output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
